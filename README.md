Fine tuned a small gpt-2 (124 million parameters) model over a dataset describing appropriate api documentations for api links. Achieved a 67% cosine similarity using small gpt-2, better performance could very likely be achieved simply by using a more powerful base model for fine tuning. 
